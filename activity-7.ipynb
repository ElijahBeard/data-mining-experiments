{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b21c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '3.13 (Python 3.13.5)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.13/bin/python3.13 -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "data = pd.read_csv(\"mutationc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc45144",
   "metadata": {},
   "source": [
    "# Part 1 - Feature Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phi(group:pd.DataFrame,t:str):\n",
    "    # helpers\n",
    "    tL = group[(group[t] == 1)]\n",
    "    tR = group[(group[t] == 0)]\n",
    "\n",
    "    n_t = group.shape[0]\n",
    "    n_t_C = group[group.iloc[:,0].str.contains(r\"^C\\d+$\",regex=True)].shape[0]\n",
    "    n_t_NC = group[group.iloc[:,0].str.contains(r\"^NC\\d+$\",regex=True)].shape[0]\n",
    "    n_tL = tL.shape[0]\n",
    "    n_tR = tR.shape[0]\n",
    "    n_tL_C = tL[tL.iloc[:,0].str.contains(r\"^C\\d+$\",regex=True)].shape[0]\n",
    "    n_tL_NC = tL[tL.iloc[:,0].str.contains(r\"^NC\\d+$\",regex=True)].shape[0]\n",
    "    n_tR_C = tR[tR.iloc[:,0].str.contains(r\"^C\\d+$\",regex=True)].shape[0]\n",
    "    n_tR_NC = tR[tR.iloc[:,0].str.contains(r\"^NC\\d+$\",regex=True)].shape[0]\n",
    "\n",
    "    P_L = n_tL / n_t\n",
    "    P_R = n_tR / n_t\n",
    "    P_C_tL = n_tL_C / n_tL if n_tL != 0 else 0\n",
    "    P_NC_tL = n_tL_NC / n_tL if n_tL != 0 else 0\n",
    "    P_C_tR = n_tR_C / n_tR if n_tR != 0 else 0\n",
    "    P_NC_tR = n_tR_NC / n_tR if n_tR != 0 else 0\n",
    "    balance = P_C_tL - P_C_tR\n",
    "    Q = abs(P_C_tL - P_C_tR) + abs(P_NC_tL - P_NC_tR)\n",
    "    PLPR = (2 * P_L * P_R)\n",
    "    phi = PLPR * Q\n",
    "\n",
    "    return {\"n(t)\":n_t,\"n(t,C)\":n_t_C,\"n(t,NC)\":n_t_NC,\n",
    "            \n",
    "            \"n(t_L)\":n_tL,\"n(t_R)\":n_tR,\"n(t_L,C)\":n_tL_C,\"n(t_R,C)\":n_tR_C,\n",
    "\n",
    "            \"n(t_L,NC)\":n_tL_NC,\"n(t_R,NC)\":n_tR_NC,\n",
    "\n",
    "            \"P_L\":P_L,\"P_R\":P_R,\"P(C|t_L)\":P_C_tL,\"P(C|t_R)\":P_C_tR,\n",
    "            \n",
    "            \"P(NC|t_L)\":P_NC_tL,\"P(NC|t_R)\":P_NC_tR,\n",
    "\n",
    "            \"2P_LP_R\":PLPR,\"Q\":Q,\"ɸ(s,t)\":phi,\"Balance\":balance}\n",
    "\n",
    "def create_feature_table(group:pd.DataFrame):\n",
    "    ft = pd.DataFrame(columns=[\n",
    "    \"n(t_L)\",\"n(t_R)\",\"n(t_L,C)\",\"n(t_R,C)\",\n",
    "    \"n(t_L,NC)\",\"n(t_R,NC)\",\n",
    "    \"P_L\",\"P_R\",\"P(C|t_L)\",\"P(C|t_R)\",\n",
    "    \"P(NC|t_L)\",\"P(NC|t_R)\",\n",
    "    \"2P_LP_R\",\"Q\",\"ɸ(s,t)\",\"Balance\"\n",
    "    ])\n",
    "\n",
    "    for t in group.columns:\n",
    "        results = compute_phi(group, t)\n",
    "        ft.loc[t] = {\n",
    "            'n(t_L)': results['n(t_L)'],\n",
    "            'n(t_R)': results['n(t_R)'],\n",
    "            'n(t_L,C)': results['n(t_L,C)'],\n",
    "            'n(t_R,C)': results['n(t_R,C)'],\n",
    "            'n(t_L,NC)': results['n(t_L,NC)'],\n",
    "            'n(t_R,NC)': results['n(t_R,NC)'],\n",
    "            'P_L': results['P_L'],\n",
    "            'P_R': results['P_R'],\n",
    "            'P(C|t_L)': results['P(C|t_L)'],\n",
    "            'P(C|t_R)': results['P(C|t_R)'],\n",
    "            'P(NC|t_L)': results['P(NC|t_L)'],\n",
    "            'P(NC|t_R)': results['P(NC|t_R)'],\n",
    "            '2P_LP_R': results['2P_LP_R'],\n",
    "            'Q': results['Q'],\n",
    "            'ɸ(s,t)': results['ɸ(s,t)'],\n",
    "            'Balance':results['Balance']\n",
    "        }\n",
    "    return ft\n",
    "\n",
    "def create_feature_table_simple(group:pd.DataFrame):\n",
    "    ft = pd.DataFrame(columns=[\n",
    "        'ɸ(s,t)',\n",
    "        'Balance'\n",
    "    ])\n",
    "\n",
    "    for t in group.columns:\n",
    "        results = compute_phi(group, t)\n",
    "        ft.loc[t] = {\n",
    "            'ɸ(s,t)': results['ɸ(s,t)'],\n",
    "            'Balance':results['Balance']\n",
    "        }\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc37338",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = create_feature_table(data)\n",
    "ft.sort_values(\"ɸ(s,t)\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40379c1",
   "metadata": {},
   "source": [
    "# Part 2 - Evaluating Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(testing:pd.DataFrame,classification:pd.Series):\n",
    "    actual = testing.iloc[:,0].replace(r'^C\\d+$','1',regex=True).replace(r'^NC\\d+$','0',regex=True).astype(int)\n",
    "    predicted = classification\n",
    "    TP = ((actual == 1) & (predicted == 1)).sum(axis=0)\n",
    "    FP = ((actual == 0) & (predicted == 1)).sum(axis=0)\n",
    "    FN = ((actual == 1) & (predicted == 0)).sum(axis=0)\n",
    "    TN = ((actual == 0) & (predicted == 0)).sum(axis=0)\n",
    "    Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    Sensitivity = TP / (TP + FN)\n",
    "    Specificity = TN / (TN + FP)\n",
    "    Precision = TP / (TP + FP)\n",
    "    Miss_rate = FN / (TP + FN)\n",
    "    False_discovery_rate = FP / (TP + FP)\n",
    "    False_omission_rate = FN / (FN + TN)\n",
    "    metrics = pd.DataFrame({\"Accuracy\":Accuracy,\"Sensitivity\":Sensitivity,\n",
    "                            \"Specificity\":Specificity,\"Precision\":Precision,\n",
    "                            \"Miss Rate\":Miss_rate,\"False Discovery Rate\":False_discovery_rate,\n",
    "                            \"False Omission Rate\":False_omission_rate},index=[0])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_process(training:pd.DataFrame,testing:pd.DataFrame):\n",
    "    results = []\n",
    "    \n",
    "    ft = create_feature_table_simple(training.iloc[1:,:])\n",
    "    F = ft.sort_values(\"ɸ(s,t)\",ascending=False).index[0]\n",
    "\n",
    "    group_A = training[(training[F] == 1)]\n",
    "    group_B = training[(training[F] == 0)]\n",
    "    gA_ft = create_feature_table(group_A)\n",
    "    gB_ft = create_feature_table(group_B)\n",
    "\n",
    "    alpha = gA_ft.sort_values(\"ɸ(s,t)\",ascending=False).index[0]\n",
    "    alpha_balance = gA_ft.sort_values(\"ɸ(s,t)\",ascending=False).Balance.head(1).sum()\n",
    "    beta = gB_ft.sort_values(\"ɸ(s,t)\",ascending=False).index[0]\n",
    "    beta_balance = gB_ft.sort_values(\"ɸ(s,t)\",ascending=False).Balance.head(1).sum()\n",
    "\n",
    "    def classify(sample):\n",
    "        if sample[F] == 1:\n",
    "            if sample[alpha] == 1:\n",
    "                return 1 if alpha_balance > 0 else 0\n",
    "            else:\n",
    "                return 1 if alpha_balance < 0 else 0\n",
    "        else:\n",
    "            if sample[beta] == 1:\n",
    "                return 1 if beta_balance > 0 else 0\n",
    "            else:\n",
    "                return 1 if beta_balance < 0 else 0\n",
    "            \n",
    "    classification = testing.apply(classify, axis=1)\n",
    "    print(f\"\\t{F}\")\n",
    "    print(f\"\\t{alpha} Balance:{alpha_balance}\")\n",
    "    print(f\"\\t{beta} Balance:{beta_balance}\")\n",
    "    return compute_metrics(testing, classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = testing_process(data,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c52463",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://media.discordapp.net/attachments/1314802602042720320/1432749366812217384/Screenshot_2025-10-28_at_11.14.15_AM.png?ex=69022f54&is=6900ddd4&hm=ccffbd88ec70a70d2cbfe61dd99eb32a839681dd1459d71f94aa7d6c34d0ccad&=&format=webp&quality=lossless&width=2304&height=1308\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7c614",
   "metadata": {},
   "source": [
    "# 3-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_testing_df(group: pd.DataFrame, folds: int):\n",
    "    if folds == 1:\n",
    "        return [group]\n",
    "    training = group.sample(frac=1/folds, random_state=42)\n",
    "    remaining = group.drop(training.index)\n",
    "    other_sets = create_training_testing_df(remaining, folds - 1)\n",
    "    return [training] + other_sets\n",
    "\n",
    "sets = create_training_testing_df(data,3)\n",
    "\n",
    "print(\"Trial 1:\")\n",
    "results_1 = testing_process(sets[0],pd.concat([sets[1],sets[2]]))\n",
    "print(\"Trial 2:\")\n",
    "results_2 = testing_process(sets[1],pd.concat([sets[0],sets[2]]))\n",
    "print(\"Trial 3:\")\n",
    "results_3 = testing_process(sets[2],pd.concat([sets[0],sets[1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_metrics = (results_1 + results_2 + results_3) / 3\n",
    "print(avg_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pandas-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
